{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "tnBB6aGGgkIt"
      },
      "outputs": [],
      "source": [
        "X_train = [\"This was awesome an Awesome movie\",\n",
        "           \"Great movie! I liked it a lot\",\n",
        "           \"Happy Ending! awesome acting by the hero\",\n",
        "           \"loved it! truly great\",\n",
        "           \"bad not upto the mark\",\n",
        "           \"could have been better\",\n",
        "           \"Surely a Disappointing movie\"]\n",
        "y_train = [1,1,1,1,0,0,0] # 1-positive, 0=negative\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "oJ6iNgCoTWwX",
        "outputId": "6125b6de-0168-4b8b-93ce-a5d4a7997b89"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['This was awesome an Awesome movie',\n",
              " 'Great movie! I liked it a lot',\n",
              " 'Happy Ending! awesome acting by the hero',\n",
              " 'loved it! truly great',\n",
              " 'bad not upto the mark',\n",
              " 'could have been better',\n",
              " 'Surely a Disappointing movie']"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMGLICHvTfkf"
      },
      "source": [
        "data cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_pOqnPETTlDu"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import RegexpTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "KdTq8-2BT8Qd"
      },
      "outputs": [],
      "source": [
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.corpus import stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-JZaRfwdUHpX",
        "outputId": "bfb48c72-bb19-41c2-e093-0f4f82a50995"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "YpvG9wHtUZb9"
      },
      "outputs": [],
      "source": [
        "tokenizer = RegexpTokenizer(r'\\w+')\n",
        "en_stopwords = set(stopwords.words('english'))\n",
        "ps =PorterStemmer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-eHOdSbQU5t9"
      },
      "outputs": [],
      "source": [
        "def getCleanedText(text):\n",
        "  text = text.lower()\n",
        "\n",
        "  #tokenize\n",
        "  tokens = tokenizer.tokenize(text)\n",
        "  new_tokens = [ token for token in tokens if token not in en_stopwords ]\n",
        "\n",
        "  stemmed_tokens = [ps.stem(tokens) for tokens in new_tokens]\n",
        "  clean_text = \" \".join(stemmed_tokens)\n",
        "  return clean_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "u6oaW191WYNn"
      },
      "outputs": [],
      "source": [
        "X_test = [\"I was happy & happy and I loved the acting in the movie\",\n",
        "          \"The movie I saw was bad\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4kyb8rRoVzpM"
      },
      "outputs": [],
      "source": [
        "X_clean = [getCleanedText(i) for i in X_train]\n",
        "Xt_clean = [getCleanedText(i) for i in X_test]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "KQ2qAVaUXCjV",
        "outputId": "fe0201f9-94aa-46d3-a886-04fdc5075a33"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['awesom awesom movi',\n",
              " 'great movi like lot',\n",
              " 'happi end awesom act hero',\n",
              " 'love truli great',\n",
              " 'bad upto mark',\n",
              " 'could better',\n",
              " 'sure disappoint movi']"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_clean"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NQX-mtTXbbi"
      },
      "source": [
        "vectorization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Fvx0MeWhXeoO"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Q4FEALVqXqC9"
      },
      "outputs": [],
      "source": [
        "cv = CountVectorizer(ngram_range=(1,2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5-shq16_X1AA"
      },
      "outputs": [],
      "source": [
        "X_vec = cv.fit_transform(X_clean).toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fxIU1_FRX9tb",
        "outputId": "ae2e92b7-29b5-4a30-d9f1-fd6af146b731"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0, 0, 2, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
              "        1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0],\n",
              "       [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "        0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0]])"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Ue0ZcEb3YGV9",
        "outputId": "2d51c9ab-b20f-4c9f-95d3-84e98e38a1f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['act', 'act hero', 'awesom', 'awesom act', 'awesom awesom', 'awesom movi', 'bad', 'bad upto', 'better', 'could', 'could better', 'disappoint', 'disappoint movi', 'end', 'end awesom', 'great', 'great movi', 'happi', 'happi end', 'hero', 'like', 'like lot', 'lot', 'love', 'love truli', 'mark', 'movi', 'movi like', 'sure', 'sure disappoint', 'truli', 'truli great', 'upto', 'upto mark']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "print(cv.get_feature_names())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "u4MKdThXYWS0"
      },
      "outputs": [],
      "source": [
        "Xt_vect = cv.transform(Xt_clean).toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "TN-2nsXRYi5-"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "MVzTLj0oYvGr"
      },
      "outputs": [],
      "source": [
        "mn = MultinomialNB()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "M9-VguhNYz6H",
        "outputId": "36eaa5d3-2078-4e23-b078-b65f860af6ec"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "MultinomialNB()"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mn.fit(X_vec,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "NNWWTV2-Y_LU"
      },
      "outputs": [],
      "source": [
        "y_pred = mn.predict(Xt_vect)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "sUPYsdSAafLd",
        "outputId": "aa37ed04-ecaf-4a48-9aec-4a0587d58b3e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 0])"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "SentimentAnalysis.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}